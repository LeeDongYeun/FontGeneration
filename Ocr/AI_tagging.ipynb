{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_tagging.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y0iYZU78K9v"
      },
      "source": [
        "Pre-trained model download link : [here](https://drive.google.com/file/d/1UDCJ3YllR3RN4QK8NTe5UoTP_s3nbde9/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrD3Wuizs4B_",
        "outputId": "6c127f63-2499-40fc-c9bf-fd4e9f5f3703"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4t78nZpxEqF",
        "outputId": "89fc0bc6-b56a-4b26-a1ba-3b17df0c97e5"
      },
      "source": [
        "!pip install tensorflow==1.12.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 55kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.33.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.18.5)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.12.4)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.35.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.4.0)\n",
            "Installing collected packages: tensorboard, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CILsLgMOlOcZ"
      },
      "source": [
        "#!/usr/bin/env python\r\n",
        "\r\n",
        "import argparse\r\n",
        "import io\r\n",
        "import os\r\n",
        "import sys\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "#SCRIPT_PATH = os.path.dirname(os.path.abspath(__file__))\r\n",
        "\r\n",
        "# Default paths.\r\n",
        "'''DEFAULT_LABEL_FILE = os.path.join(\r\n",
        "    SCRIPT_PATH, '/gdrive/My Drive/CS470/teamai/labels/2350-common-hangul.txt'\r\n",
        ")\r\n",
        "DEFAULT_GRAPH_FILE = os.path.join(\r\n",
        "    SCRIPT_PATH, '/gdrive/My Drive/CS470/teamai/saved-model/optimized_hangul_tensorflow.pb'\r\n",
        ")'''\r\n",
        "\r\n",
        "\r\n",
        "def read_image(file):\r\n",
        "    \"\"\"Read an image file and convert it into a 1-D floating point array.\"\"\"\r\n",
        "    file_content = tf.read_file(file)\r\n",
        "    image = tf.image.decode_jpeg(file_content, channels=1)\r\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\r\n",
        "    image = tf.reshape(image, (1, 64*64))\r\n",
        "    return image\r\n",
        "\r\n",
        "\r\n",
        "def classify(img_file, label_file, graph_file):\r\n",
        "    \"\"\"Classify a character.\r\n",
        "\r\n",
        "    This method will import the saved model from the given graph file, and will\r\n",
        "    pass in the given image pixels as input for the classification. The top\r\n",
        "    five predictions will be printed.\r\n",
        "    \"\"\"\r\n",
        "    labels = io.open(label_file,\r\n",
        "                     'r', encoding='utf-8').read().splitlines()\r\n",
        "\r\n",
        "    if not os.path.isfile(img_file):\r\n",
        "        print('Error: Image %s not found.' % img_file)\r\n",
        "        sys.exit(1)\r\n",
        "\r\n",
        "    # Load graph and parse file.\r\n",
        "    with tf.gfile.GFile(graph_file, \"rb\") as f:\r\n",
        "        graph_def = tf.GraphDef()\r\n",
        "        graph_def.ParseFromString(f.read())\r\n",
        "\r\n",
        "    with tf.Graph().as_default() as graph:\r\n",
        "        tf.import_graph_def(\r\n",
        "            graph_def,\r\n",
        "            input_map=None,\r\n",
        "            return_elements=None,\r\n",
        "            name='hangul-model',\r\n",
        "            producer_op_list=None\r\n",
        "        )\r\n",
        "\r\n",
        "    # Get relevant nodes.\r\n",
        "    x = graph.get_tensor_by_name('hangul-model/input:0')\r\n",
        "    y = graph.get_tensor_by_name('hangul-model/output:0')\r\n",
        "    keep_prob = graph.get_tensor_by_name('hangul-model/keep_prob:0')\r\n",
        "\r\n",
        "    image = read_image(img_file)\r\n",
        "    sess = tf.InteractiveSession()\r\n",
        "    image_array = sess.run(image)\r\n",
        "    sess.close()\r\n",
        "    with tf.Session(graph=graph) as graph_sess:\r\n",
        "        predictions = graph_sess.run(y, feed_dict={x: image_array,\r\n",
        "                                                   keep_prob: 1.0})\r\n",
        "        prediction = predictions[0]\r\n",
        "\r\n",
        "    # Get the indices that would sort the array, then only get the indices that\r\n",
        "    # correspond to the top 5 predictions.\r\n",
        "    sorted_indices = prediction.argsort()[::-1][:5]\r\n",
        "    for index in sorted_indices:\r\n",
        "        label = labels[index]\r\n",
        "        confidence = prediction[index]\r\n",
        "        return label\r\n",
        "\r\n",
        "#change the path names in classify for your own file\r\n",
        "# second arguement should be the label file, third arguement should be the pre-trained model\r\n",
        "def tag(image_file):\r\n",
        "    return classify(image_file, '/gdrive/My Drive/CS470/teamai/labels/2350-common-hangul.txt', '/gdrive/My Drive/CS470/teamai/saved-model/optimized_hangul_tensorflow.pb')  \r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKtsfaymwfv2"
      },
      "source": [
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import glob\r\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmi8W9LSwp9e"
      },
      "source": [
        "#the path in glob should be the path to the image files, also change png into the img files state\r\n",
        "images = glob.glob('/gdrive/MyDrive/CS470/teamai/h_letter/h_weird/*.png')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW6h4L-swsLB",
        "outputId": "35586331-311c-46ae-fc8c-6c8c4db0025d"
      },
      "source": [
        "#this will save the images with the tagged unicode into the directory you insert\r\n",
        "for img in images:\r\n",
        "  image = img\r\n",
        "  cvimg = cv2.imread(image)\r\n",
        "  dst = cv2.bitwise_not(cvimg)\r\n",
        "  cv2.imwrite( \"checking.jpg\", dst )\r\n",
        "  newimg = Image.open(\"checking.jpg\")\r\n",
        "  resized = newimg.resize((64,64))\r\n",
        "\r\n",
        "  data = np.array(resized)\r\n",
        "  red, green, blue = data[:,:,0], data[:,:,1],data[:,:,2]\r\n",
        "  for i in range(64):\r\n",
        "    for j in range(64):\r\n",
        "      imsi = data[i][j]\r\n",
        "      if (int(imsi[0])+int(imsi[1])+int(imsi[2])) < 300:\r\n",
        "        data[i][j] = [0,0,0]\r\n",
        "  newimg = Image.fromarray(data)\r\n",
        "\r\n",
        "  newimg.save('new1.jpeg')\r\n",
        "  letter = tag('/content/new1.jpeg')\r\n",
        "  uni = 'uni' + str(hex(ord(letter)))[2:].upper()\r\n",
        "  #the path will be the directory you want to save the img files\r\n",
        "  path = '/gdrive/MyDrive/CS470/teamai/new_external/save_files/'\r\n",
        "  cvimg = cv2.imread('new1.jpeg')\r\n",
        "  dst = cv2.bitwise_not(cvimg)\r\n",
        "  cv2.imwrite( path+uni+'.jpg', dst )\r\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}