{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oi2VYPjn34P"
      },
      "source": [
        "Trained model download link : [15epoch](https://drive.google.com/file/d/1WNVQy4bvtg4VmDQKLF3-eJfKROltM9TI/view?usp=sharing), [25epoch](https://drive.google.com/file/d/1TVxYdy_XvyzdT3YsjT-gYar123nCU0Hj/view?usp=sharing) model\r\n",
        "\r\n",
        "Pre-trained model download link : [15epoch](https://drive.google.com/file/d/1UDCJ3YllR3RN4QK8NTe5UoTP_s3nbde9/view?usp=sharing)\r\n",
        "\r\n",
        "Run the process in order and change the file paths into your own path. Files will be attached in the github folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMfCEj9pn0BJ",
        "outputId": "44c0cb36-b2a6-413d-da19-70bb3b9b061e"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80N4xnciqp0c",
        "outputId": "cd0c8ed1-4a8f-4e2b-d565-bb4b304fa7bc"
      },
      "source": [
        "!pip install tensorflow==1.12.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 67kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.10.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.18.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.36.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.34.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.12.4)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.4.0)\n",
            "Installing collected packages: keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssC8R7j5n0n_"
      },
      "source": [
        "#!/usr/bin/env python\r\n",
        "\r\n",
        "import argparse\r\n",
        "import io\r\n",
        "import os\r\n",
        "import sys\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "\r\n",
        "def read_image(file):\r\n",
        "    \"\"\"Read an image file and convert it into a 1-D floating point array.\"\"\"\r\n",
        "    file_content = tf.read_file(file)\r\n",
        "    image = tf.image.decode_jpeg(file_content, channels=1)\r\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\r\n",
        "    image = tf.reshape(image, (1, 64*64))\r\n",
        "    return image\r\n",
        "\r\n",
        "\r\n",
        "def classify(img_file, label_file, graph_file):\r\n",
        "    \"\"\"Classify a character.\r\n",
        "\r\n",
        "    This method will import the saved model from the given graph file, and will\r\n",
        "    pass in the given image pixels as input for the classification. The top\r\n",
        "    five predictions will be printed.\r\n",
        "    \"\"\"\r\n",
        "    labels = io.open(label_file,\r\n",
        "                     'r', encoding='utf-8').read().splitlines()\r\n",
        "\r\n",
        "    if not os.path.isfile(img_file):\r\n",
        "        print('Error: Image %s not found.' % img_file)\r\n",
        "        sys.exit(1)\r\n",
        "\r\n",
        "    # Load graph and parse file.\r\n",
        "    with tf.gfile.GFile(graph_file, \"rb\") as f:\r\n",
        "        graph_def = tf.GraphDef()\r\n",
        "        graph_def.ParseFromString(f.read())\r\n",
        "\r\n",
        "    with tf.Graph().as_default() as graph:\r\n",
        "        tf.import_graph_def(\r\n",
        "            graph_def,\r\n",
        "            input_map=None,\r\n",
        "            return_elements=None,\r\n",
        "            name='hangul-model',\r\n",
        "            producer_op_list=None\r\n",
        "        )\r\n",
        "\r\n",
        "    # Get relevant nodes.\r\n",
        "    x = graph.get_tensor_by_name('hangul-model/input:0')\r\n",
        "    y = graph.get_tensor_by_name('hangul-model/output:0')\r\n",
        "    keep_prob = graph.get_tensor_by_name('hangul-model/keep_prob:0')\r\n",
        "\r\n",
        "    image = read_image(img_file)\r\n",
        "    sess = tf.InteractiveSession()\r\n",
        "    image_array = sess.run(image)\r\n",
        "    sess.close()\r\n",
        "    with tf.Session(graph=graph) as graph_sess:\r\n",
        "        predictions = graph_sess.run(y, feed_dict={x: image_array,\r\n",
        "                                                   keep_prob: 1.0})\r\n",
        "        prediction = predictions[0]\r\n",
        "\r\n",
        "    # Get the indices that would sort the array, then only get the indices that\r\n",
        "    # correspond to the top 5 predictions.\r\n",
        "    sorted_indices = prediction.argsort()[::-1][:5]\r\n",
        "    for index in sorted_indices:\r\n",
        "        label = labels[index]\r\n",
        "        confidence = prediction[index]\r\n",
        "        return label\r\n",
        "\r\n",
        "# Change the path names in classify for your own file\r\n",
        "# second arguement should be the label file, third arguement should be the pre-trained model\r\n",
        "def tag(image_file):\r\n",
        "    return classify(image_file, '/gdrive/My Drive/CS470/teamai/labels/2350-common-hangul.txt', '/gdrive/My Drive/CS470/teamai/save_model_trained/optimized_hangul_tensorflow_2350_25.pb')\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXVMApSKoYLD"
      },
      "source": [
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import glob\r\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpU7UUYhQpKy"
      },
      "source": [
        "Input image files should be named as the correct Korean character to evaluated the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBDe0x3zobz1"
      },
      "source": [
        "#the path in glob should be the path to the image files, also change png into the img files state\r\n",
        "images = glob.glob('/gdrive/MyDrive/CS470/teamai/test_letter/all_test_h/*.png')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr7fZ6MbPg17"
      },
      "source": [
        "The unicode type of the parsed image path name is not the same as the model generated result. So the accuracy is now calculated by human labor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZC7r7MJoxHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22081705-645e-45c6-df0b-508805ec232c"
      },
      "source": [
        "#this will save the images with the tagged unicode into the directory you insert\r\n",
        "count = 0\r\n",
        "for img in images:\r\n",
        "  image = img\r\n",
        "  cvimg = cv2.imread(image)\r\n",
        "  dst = cv2.bitwise_not(cvimg)\r\n",
        "  cv2.imwrite( \"checking.jpg\", dst )\r\n",
        "  newimg = Image.open(\"checking.jpg\")\r\n",
        "  resized = newimg.resize((64,64))\r\n",
        "\r\n",
        "  data = np.array(resized)\r\n",
        "  red, green, blue = data[:,:,0], data[:,:,1],data[:,:,2]\r\n",
        "  for i in range(64):\r\n",
        "    for j in range(64):\r\n",
        "      imsi = data[i][j]\r\n",
        "      if (int(imsi[0])+int(imsi[1])+int(imsi[2])) < 300:\r\n",
        "        data[i][j] = [0,0,0]\r\n",
        "  newimg1 = Image.fromarray(data)\r\n",
        "\r\n",
        "  newimg1.save('new1.jpeg')\r\n",
        "  tagged_letter = tag('/content/new1.jpeg')\r\n",
        "  #the path will be the directory you want to save the img files\r\n",
        "  name = img.split('/')[-1].split('.')[0]\r\n",
        "  print(tagged_letter, name)\r\n",
        "  count += 1\r\n",
        "print(count)\r\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "은 은\n",
            "걔 개\n",
            "울 울\n",
            "가 가\n",
            "에 에\n",
            "서 서\n",
            "녀 녀\n",
            "를 를\n",
            "보 보\n",
            "자 자\n",
            "윤 윤\n",
            "초 초\n",
            "시 시\n",
            "증 증\n",
            "손 손\n",
            "딸 딸\n",
            "슥 수\n",
            "있 있\n",
            "었 었\n",
            "잠 잠\n",
            "고 고\n",
            "장 장\n",
            "지 지\n",
            "기 기\n",
            "듯 듯\n",
            "써 써\n",
            "철 칠\n",
            "학 학\n",
            "아 아\n",
            "오 오\n",
            "어 어\n",
            "제 제\n",
            "까 까\n",
            "니 니\n",
            "둑 둑\n",
            "모 모\n",
            "르 르\n",
            "냥 냥\n",
            "날 날\n",
            "쎄 쎄\n",
            "안 만\n",
            "물 물\n",
            "켜 켜\n",
            "밴 낸\n",
            "번 번\n",
            "허 허\n",
            "탕 탕\n",
            "재 재\n",
            "뫼 미\n",
            "양 양\n",
            "움 움\n",
            "킨 킨\n",
            "처 처\n",
            "렁 럼\n",
            "건 건\n",
            "너 너\n",
            "사 사\n",
            "랍 람\n",
            "킬 길\n",
            "비 비\n",
            "려 러\n",
            "아 다\n",
            "속 속\n",
            "엇 엇\n",
            "하 하\n",
            "조 조\n",
            "약 약\n",
            "돌 돌\n",
            "리 리\n",
            "벌 벌\n",
            "퍽 떡\n",
            "나 나\n",
            "꽐 팔\n",
            "짝 짝\n",
            "징 징\n",
            "겅 검\n",
            "간 간\n",
            "홱 홱\n",
            "며 며\n",
            "바 바\n",
            "행 행\n",
            "주 주\n",
            "읗 음\n",
            "종 좀\n",
            "늦 늦\n",
            "뎨 데\n",
            "세 세\n",
            "터 터\n",
            "걷 걷\n",
            "록 목\n",
            "털 덜\n",
            "마 마\n",
            "희 희\n",
            "한 한\n",
            "찮 참\n",
            "빤 빤\n",
            "들 들\n",
            "여 여\n",
            "얼 얼\n",
            "굴 굴\n",
            "끼 끼\n",
            "도 도\n",
            "걸 걸\n",
            "교 교\n",
            "것 것\n",
            "난 난\n",
            "는 는\n",
            "늘 늘\n",
            "네 네\n",
            "더 더\n",
            "라 라\n",
            "런 런\n",
            "렸 렸\n",
            "슭 슭\n",
            "못 못\n",
            "알 알\n",
            "앉 앉\n",
            "을 을\n",
            "째 째\n",
            "키 키\n",
            "쥡 집\n",
            "본 본\n",
            "로 로\n",
            "문 무\n",
            "킬 킬\n",
            "이 이\n",
            "얀 얀\n",
            "고 그\n",
            "뛰 뛰\n",
            "요 요\n",
            "웨 웨\n",
            "꾼 꾸\n",
            "132\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}