{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oi2VYPjn34P"
      },
      "source": [
        "Pre-trained model download link : [15epoch](https://drive.google.com/file/d/1WNVQy4bvtg4VmDQKLF3-eJfKROltM9TI/view?usp=sharing), [25epoch](https://drive.google.com/file/d/1TVxYdy_XvyzdT3YsjT-gYar123nCU0Hj/view?usp=sharing) model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMfCEj9pn0BJ",
        "outputId": "050b329e-22a8-42df-ef97-e168d5105d90"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80N4xnciqp0c",
        "outputId": "bf422d20-62b4-45b6-dd0c-b0b997dc758b"
      },
      "source": [
        "!pip install tensorflow==1.12.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.10.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.35.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.33.2)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (50.3.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.4.0)\n",
            "Installing collected packages: keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssC8R7j5n0n_"
      },
      "source": [
        "#!/usr/bin/env python\r\n",
        "\r\n",
        "import argparse\r\n",
        "import io\r\n",
        "import os\r\n",
        "import sys\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "#SCRIPT_PATH = os.path.dirname(os.path.abspath(__file__))\r\n",
        "\r\n",
        "# Default paths.\r\n",
        "'''DEFAULT_LABEL_FILE = os.path.join(\r\n",
        "    SCRIPT_PATH, '/gdrive/My Drive/CS470/teamai/labels/2350-common-hangul.txt'\r\n",
        ")\r\n",
        "DEFAULT_GRAPH_FILE = os.path.join(\r\n",
        "    SCRIPT_PATH, '/gdrive/My Drive/CS470/teamai/saved-model/optimized_hangul_tensorflow.pb'\r\n",
        ")'''\r\n",
        "\r\n",
        "\r\n",
        "def read_image(file):\r\n",
        "    \"\"\"Read an image file and convert it into a 1-D floating point array.\"\"\"\r\n",
        "    file_content = tf.read_file(file)\r\n",
        "    image = tf.image.decode_jpeg(file_content, channels=1)\r\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\r\n",
        "    image = tf.reshape(image, (1, 64*64))\r\n",
        "    return image\r\n",
        "\r\n",
        "\r\n",
        "def classify(img_file, label_file, graph_file):\r\n",
        "    \"\"\"Classify a character.\r\n",
        "\r\n",
        "    This method will import the saved model from the given graph file, and will\r\n",
        "    pass in the given image pixels as input for the classification. The top\r\n",
        "    five predictions will be printed.\r\n",
        "    \"\"\"\r\n",
        "    labels = io.open(label_file,\r\n",
        "                     'r', encoding='utf-8').read().splitlines()\r\n",
        "\r\n",
        "    if not os.path.isfile(img_file):\r\n",
        "        print('Error: Image %s not found.' % img_file)\r\n",
        "        sys.exit(1)\r\n",
        "\r\n",
        "    # Load graph and parse file.\r\n",
        "    with tf.gfile.GFile(graph_file, \"rb\") as f:\r\n",
        "        graph_def = tf.GraphDef()\r\n",
        "        graph_def.ParseFromString(f.read())\r\n",
        "\r\n",
        "    with tf.Graph().as_default() as graph:\r\n",
        "        tf.import_graph_def(\r\n",
        "            graph_def,\r\n",
        "            input_map=None,\r\n",
        "            return_elements=None,\r\n",
        "            name='hangul-model',\r\n",
        "            producer_op_list=None\r\n",
        "        )\r\n",
        "\r\n",
        "    # Get relevant nodes.\r\n",
        "    x = graph.get_tensor_by_name('hangul-model/input:0')\r\n",
        "    y = graph.get_tensor_by_name('hangul-model/output:0')\r\n",
        "    keep_prob = graph.get_tensor_by_name('hangul-model/keep_prob:0')\r\n",
        "\r\n",
        "    image = read_image(img_file)\r\n",
        "    sess = tf.InteractiveSession()\r\n",
        "    image_array = sess.run(image)\r\n",
        "    sess.close()\r\n",
        "    with tf.Session(graph=graph) as graph_sess:\r\n",
        "        predictions = graph_sess.run(y, feed_dict={x: image_array,\r\n",
        "                                                   keep_prob: 1.0})\r\n",
        "        prediction = predictions[0]\r\n",
        "\r\n",
        "    # Get the indices that would sort the array, then only get the indices that\r\n",
        "    # correspond to the top 5 predictions.\r\n",
        "    sorted_indices = prediction.argsort()[::-1][:5]\r\n",
        "    for index in sorted_indices:\r\n",
        "        label = labels[index]\r\n",
        "        confidence = prediction[index]\r\n",
        "        return label\r\n",
        "\r\n",
        "#change the path names in classify for your own file\r\n",
        "# second arguement should be the label file, third arguement should be the pre-trained model\r\n",
        "def tag(image_file):\r\n",
        "    return classify(image_file, '/gdrive/My Drive/CS470/teamai/labels/2350-common-hangul.txt', '/gdrive/My Drive/CS470/teamai/save_model_trained/optimized_hangul_tensorflow_2350_15.pb')\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXVMApSKoYLD"
      },
      "source": [
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import glob\r\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpU7UUYhQpKy"
      },
      "source": [
        "Input image files should be named as the correct Korean character to evaluated the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBDe0x3zobz1"
      },
      "source": [
        "#the path in glob should be the path to the image files, also change png into the img files state\r\n",
        "images = glob.glob('/gdrive/MyDrive/CS470/teamai/test_letter/all_test_ex/*.jpg')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr7fZ6MbPg17"
      },
      "source": [
        "The unicode type of the parsed image path name is not the same as the model generated result. So the accuracy is now calculated by human labor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZC7r7MJoxHj",
        "outputId": "ff5f3993-bd1b-45d0-eae8-d69c573733f0"
      },
      "source": [
        "#this will save the images with the tagged unicode into the directory you insert\r\n",
        "count = 0\r\n",
        "for img in images:\r\n",
        "  image = img\r\n",
        "  cvimg = cv2.imread(image)\r\n",
        "  dst = cv2.bitwise_not(cvimg)\r\n",
        "  cv2.imwrite( \"checking.jpg\", dst )\r\n",
        "  newimg = Image.open(\"checking.jpg\")\r\n",
        "  resized = newimg.resize((64,64))\r\n",
        "\r\n",
        "  data = np.array(resized)\r\n",
        "  red, green, blue = data[:,:,0], data[:,:,1],data[:,:,2]\r\n",
        "  for i in range(64):\r\n",
        "    for j in range(64):\r\n",
        "      imsi = data[i][j]\r\n",
        "      if (int(imsi[0])+int(imsi[1])+int(imsi[2])) < 300:\r\n",
        "        data[i][j] = [0,0,0]\r\n",
        "  newimg1 = Image.fromarray(data)\r\n",
        "\r\n",
        "  newimg1.save('new1.jpeg')\r\n",
        "  tagged_letter = tag('/content/new1.jpeg')\r\n",
        "  #the path will be the directory you want to save the img files\r\n",
        "  name = img.split('/')[-1].split('.')[0]\r\n",
        "  print(tagged_letter, name)\r\n",
        "  count += 1\r\n",
        "print(count)\r\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "서 세\n",
            "기 기\n",
            "유 류\n",
            "의 의\n",
            "과 과\n",
            "둣 술\n",
            "읜 은\n",
            "인 인\n",
            "생 생\n",
            "학 학\n",
            "큰 을\n",
            "임 임\n",
            "다 다\n",
            "아 아\n",
            "긴 고\n",
            "도 도\n",
            "보 보\n",
            "부 부\n",
            "책 책\n",
            "꼬 언\n",
            "네 니\n",
            "김 그\n",
            "끈 러\n",
            "나 나\n",
            "최 최\n",
            "귄 근\n",
            "눈 눈\n",
            "닌 신\n",
            "곡 속\n",
            "발 발\n",
            "전 전\n",
            "괴 리\n",
            "핸 행\n",
            "까 까\n",
            "지 지\n",
            "의 미\n",
            "유 우\n",
            "하 하\n",
            "누 수\n",
            "울 물\n",
            "져 적\n",
            "해 해\n",
            "꾜 좌\n",
            "되 되\n",
            "겆 것\n",
            "에 에\n",
            "즉 즉\n",
            "절 질\n",
            "풍 풍\n",
            "쟈 주\n",
            "영 영\n",
            "챦 향\n",
            "여 예\n",
            "어 어\n",
            "들 들\n",
            "묘 요\n",
            "자 자\n",
            "판 만\n",
            "외 외\n",
            "나 내\n",
            "난 난\n",
            "게 게\n",
            "갑 람\n",
            "롭 롭\n",
            "사 사\n",
            "화 화\n",
            "목 목\n",
            "한 한\n",
            "가 가\n",
            "정 정\n",
            "더 더\n",
            "인 일\n",
            "셔 서\n",
            "종 중\n",
            "네 비\n",
            "면 면\n",
            "윤 윤\n",
            "덕 덕\n",
            "히 히\n",
            "롯 롯\n",
            "성 성\n",
            "얻 엄\n",
            "죤 존\n",
            "특 특\n",
            "간 간\n",
            "관 관\n",
            "명 명\n",
            "닐 실\n",
            "앗 앗\n",
            "채 채\n",
            "녀 려\n",
            "닐 실1\n",
            "챦 않\n",
            "졔 제\n",
            "치 치\n",
            "뿐 뿐\n",
            "쁠 불\n",
            "개 개\n",
            "귀 귀\n",
            "뚜 뛰\n",
            "등 등\n",
            "판 단\n",
            "능 능\n",
            "놓 놓\n",
            "례 례\n",
            "오 모\n",
            "읖 른\n",
            "여 여\n",
            "야 야\n",
            "있 있\n",
            "쁨 쁨\n",
            "친 친\n",
            "켜 켜\n",
            "총 충\n",
            "첫 청\n",
            "회 회\n",
            "현 현\n",
            "할 할\n",
            "표 또\n",
            "루 루\n",
            "여 며\n",
            "못 못\n",
            "본 본\n",
            "됴 순\n",
            "십 심\n",
            "쟝 장\n",
            "준 준\n",
            "죡 족\n",
            "접 집\n",
            "키 키\n",
            "꾐 필\n",
            "전 진\n",
            "들 를\n",
            "보 복\n",
            "화 후\n",
            "135\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}